{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HExLQrE4ZxR"
      },
      "source": [
        "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LuKrFzC4ZxV"
      },
      "source": [
        "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wES-wWN4ZxX"
      },
      "source": [
        "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
        "\n",
        "Check the documentation for better understanding of these attributes: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
        "\n",
        "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
        "\n",
        "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
        "\n",
        "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
        "\n",
        "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
        "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
        "\n",
        "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
        "\n",
        "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z830CfMk4Zxa"
      },
      "source": [
        "## Task E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuBxHiCQ4Zxc"
      },
      "source": [
        "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
        "\n",
        "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
        "\n",
        "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fCgMNEvI4Zxf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ANUNIqCe4Zxn"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uchWYcepN-w-",
        "outputId": "aea13fa7-ccc1-4f7c-dbbc-02cf1939ba6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train (3000, 5)\n",
            "y_train (3000,)\n",
            "x_cv (1000, 5)\n",
            "y_cv (1000,)\n",
            "x_test (1000, 5)\n",
            "y_test (1000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,X_test,y_train,Y_test=train_test_split(X,y,test_size=0.40,stratify=y,random_state=42 )\n",
        "x_cv,x_test,y_cv,y_test=train_test_split(X_test,Y_test,test_size=0.5,stratify=Y_test,random_state=42)\n",
        "print('x_train',x_train.shape)\n",
        "print('y_train',y_train.shape)\n",
        "print('x_cv',x_cv.shape)\n",
        "print('y_cv',y_cv.shape)\n",
        "print('x_test',x_test.shape)\n",
        "print('y_test',y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHie1zqH4Zxt"
      },
      "source": [
        "### Pseudo code\n",
        "\n",
        "clf = SVC(gamma=0.001, C=100.)<br>\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
        "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
        "    \n",
        "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
        "\n",
        "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#standardising before applying svm for easy calcululation \n",
        "from sklearn import preprocessing\n",
        "normalizer = preprocessing.Normalizer()\n",
        "x_train= normalizer.fit_transform(x_train)\n",
        "x_train.shape\n",
        "\n",
        "from sklearn import preprocessing\n",
        "normalizer = preprocessing.Normalizer()\n",
        "x_cv= normalizer.fit_transform(x_cv)\n",
        "x_cv.shape\n",
        "\n",
        "from sklearn import preprocessing\n",
        "normalizer = preprocessing.Normalizer()\n",
        "x_test= normalizer.fit_transform(x_test)\n",
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P2_ScslxI34",
        "outputId": "16640da3-f2fd-4d4c-f15a-ec74269646b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h43kDT3M41u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc8f93d-d0ce-4d66-aa15-ba0b30c82e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "support_vectors (667, 5)\n"
          ]
        }
      ],
      "source": [
        "# you can write your code here\n",
        "import random\n",
        "model_clf = SVC(gamma=0.001, C=100,kernel=\"rbf\")\n",
        "model_clf.fit(x_train, y_train)\n",
        "y_pred = model_clf.predict(x_test)\n",
        "print(\"support_vectors\",model_clf.support_vectors_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x7YcnihPN-xB",
        "outputId": "df0c3873-9bd5-4a03-ed90-00a510bb39b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[655  42]\n",
            " [ 25 278]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95       697\n",
            "           1       0.87      0.92      0.89       303\n",
            "\n",
            "    accuracy                           0.93      1000\n",
            "   macro avg       0.92      0.93      0.92      1000\n",
            "weighted avg       0.93      0.93      0.93      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ijmIii57N-xC"
      },
      "outputs": [],
      "source": [
        "def decision_function(x_cv):\n",
        "    alphas = model_clf.dual_coef_[0]\n",
        "    decision_function = []\n",
        "    for dp in x_cv:\n",
        "        sum = model_clf.intercept_[0]\n",
        "        for i,supvec in enumerate(model_clf.support_vectors_):\n",
        "            norm = np.linalg.norm(supvec - dp)**2\n",
        "            kernel = np.exp(-0.001*norm)\n",
        "            #print(kernel)\n",
        "            sum += (alphas[i]*kernel)\n",
        "        #print(sum)\n",
        "        decision_function.append(sum)\n",
        "        \n",
        "    return np.array(decision_function)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"decision_function output shape\",model_clf.decision_function(x_cv).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czAUnGovxqo2",
        "outputId": "e5595c90-a337-4852-ae2b-0c5edde33355"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision_function output shape (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dual coeff shape\",model_clf.dual_coef_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ltMzSzx1y9",
        "outputId": "aace26b9-c81e-4c1b-8c07-1457f3be3f99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dual coeff shape (1, 667)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0vqvEkjnN-xB",
        "outputId": "1c9924e6-b523-4752-d528-5cf5e936cabc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.0089086   1.50715859  1.99033718 -1.65137204  2.21327284 -1.41470309\n",
            " -2.54105833 -1.91920896 -2.97507754 -2.66662818]\n"
          ]
        }
      ],
      "source": [
        "print(model_clf.decision_function(x_cv)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D5w-5XAAN-xC",
        "outputId": "011f69d1-2ba2-4673-f0dc-1d224d8da2ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.0089086   1.50715859  1.99033718 -1.65137204  2.21327284 -1.41470309\n",
            " -2.54105833 -1.91920896 -2.97507754 -2.66662818]\n"
          ]
        }
      ],
      "source": [
        "F_cv = decision_function(x_cv)\n",
        "print(F_cv[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0bKCboN4Zxu"
      },
      "source": [
        "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMn7OEN94Zxw"
      },
      "source": [
        "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
        "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0n5EFkx4Zxz"
      },
      "source": [
        "## TASK F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0HOqVJq4Zx1"
      },
      "source": [
        "\n",
        "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
        "\n",
        "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
        "\n",
        "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
        "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
        "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
        "\n",
        "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S9P-3LiIN-xE",
        "outputId": "8d1bc16f-1f68-4b30-d473-a1d61d7e8f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive classes in y_train: 908\n",
            "Number of negative classes in y_train 2092\n",
            "****************************************\n",
            "Number of positive classes in y_cv: 303\n",
            "Number of negative classes in y_cv 92\n",
            "(1000,)\n"
          ]
        }
      ],
      "source": [
        "Np=y_train[y_train>0].sum()\n",
        "Nn=len(y_train)-Np\n",
        "print(\"Number of positive classes in y_train:\",Np)\n",
        "print(\"Number of negative classes in y_train\",Nn)\n",
        "print(\"**\"*20)\n",
        "Yp = (Np+1)/(Np+2)\n",
        "Yn = 1/(Nn+2)\n",
        "\n",
        "modified_ycv = []\n",
        "\n",
        "ycv_Np=y_cv[y_cv>0].sum()\n",
        "ycv_Nn=len(y_cv)-Np\n",
        "print(\"Number of positive classes in y_cv:\",ycv_Np)\n",
        "print(\"Number of negative classes in y_cv\",ycv_Nn)\n",
        "\n",
        "for y in y_cv:\n",
        "    if y > 0:\n",
        "        modified_ycv.append(Yp)\n",
        "    else:\n",
        "        modified_ycv.append(Yn)\n",
        "modified_ycv = np.array(modified_ycv)\n",
        "print(modified_ycv.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5JjsJCgjN-xE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero\n",
        "    #initialize bias to zero\n",
        "    w = np.zeros_like(dim).reshape(1,-1)\n",
        "    b = 0\n",
        "    return w,b\n",
        "\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    result = 1/(1+np.exp(-z))\n",
        "    return result\n",
        "\n",
        "def logloss(y_true,y_pred,w,b):\n",
        "    N = len(y_true)\n",
        "    sum_log_loss=0\n",
        "    for index in range(N):\n",
        "        arg1=sigmoid(w*y_pred[index]+b)\n",
        "        arg2=(1-arg1)+10e-6\n",
        "        sum_log_loss +=(y_true[index] * math.log10(arg1)+(1-y_true[index]) * math.log10(arg2))\n",
        "    return -sum_log_loss/N\n",
        "\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    z= (w*x) + b\n",
        "    dw = x * (y- sigmoid(z)) - alpha * w/N\n",
        "    return dw\n",
        "\n",
        "def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "    z= (w*x+b) + b\n",
        "    db = y - sigmoid(z)\n",
        "    return db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1rfKnEWlN-xF"
      },
      "outputs": [],
      "source": [
        "def train(X_train,y_train,epochs,alpha,eta0):\n",
        "    log_loss=[]\n",
        "    w,b=0,0\n",
        "    for epoch in range(1,epochs):\n",
        "        predicted=[]\n",
        "        #print(w,b)\n",
        "        for index in range(len(X_train)):\n",
        "            grad_w = gradient_dw(X_train[index],y_train[index],w,b,alpha,len(X_train))\n",
        "            grad_b = gradient_db(X_train[index],y_train[index],w,b)\n",
        "            w_new = w - eta0 * grad_w\n",
        "            b_new = b - eta0 * grad_b\n",
        "            w=w_new\n",
        "            b=b_new\n",
        "\n",
        "        for index in range(len(X_train)):\n",
        "            z = w*X_train[index] + b\n",
        "            #print(z)\n",
        "            pred = round(sigmoid(z),4)\n",
        "            #print(pred)\n",
        "            predicted.append(pred)\n",
        "            \n",
        "        loss=logloss(y_train,predicted,w,b)\n",
        "        #print(loss)\n",
        "        log_loss.append(loss)\n",
        "        \n",
        "    return log_loss,w,b "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QAIKQWmiN-xF",
        "outputId": "875f4a91-cf37-4380-accc-6d5ce94cb7ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_loss: [0.20722601908389143, 0.13038572138377574, 0.11138093043054262, 0.11755836450298886, 0.1337858904612123, 0.1544454752424023, 0.1773649897170194, 0.2015938708890187, 0.22665299027003022, 0.25228412287684737, 0.2783232445175099, 0.3046631789596858, 0.33121521914742985, 0.3579236050359715, 0.384730631044754, 0.411612027641064, 0.43852849566163793, 0.4654613042428664, 0.4923783496600959]\n",
            "\n",
            "weights: -32.44837406453687\n",
            "\n",
            "bias_term: 8.031802075095545\n"
          ]
        }
      ],
      "source": [
        "log_loss, w, b=train(X_train=F_cv,y_train=modified_ycv,epochs=20,alpha=0.001,eta0=0.001)\n",
        "print('log_loss:',log_loss)\n",
        "print('\\nweights:',w)\n",
        "print('\\nbias_term:',b) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xfTHNC_VN-xG",
        "outputId": "65152cb6-a76a-41bd-b6b5-5f9f45c70729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_loss: [0.29837695687702215, 0.29396320989393393, 0.28751316450161146, 0.2789848583836649, 0.26862584457009014, 0.2569187260663492, 0.2444463606631799, 0.23175423965201067, 0.21927193941819603, 0.20729662227091586, 0.19601436591193927, 0.1855257293423869, 0.17587550582665903, 0.16707161808163876, 0.15909613857302213, 0.15191973772347742, 0.14550251001092748, 0.1398006272366454, 0.13476764137094785]\n",
            "\n",
            "weights: -2.7866793600250412\n",
            "\n",
            "bias_term: 0.7585345196202196\n"
          ]
        }
      ],
      "source": [
        "log_loss, w, b=train(X_train=F_cv,y_train=modified_ycv,epochs=20,alpha=0.0001,eta0=0.0001)\n",
        "print('log_loss:',log_loss)\n",
        "print('\\nweights:',w)\n",
        "print('\\nbias_term:',b) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGFTNkOmd9l0",
        "outputId": "5ac9a75b-dadb-4171-8512-39fc1b529508"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29837695687702215,\n",
              " 0.29396320989393393,\n",
              " 0.28751316450161146,\n",
              " 0.2789848583836649,\n",
              " 0.26862584457009014,\n",
              " 0.2569187260663492,\n",
              " 0.2444463606631799,\n",
              " 0.23175423965201067,\n",
              " 0.21927193941819603,\n",
              " 0.20729662227091586]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.grid()\n",
        "plt.plot(np.arange(1,20),log_loss,'bo-',label='Loss',linewidth=3)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Epoch vs Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ms6Xk1JbeRmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0fb64590-adcb-4ff8-fdd6-0b5a6c2c1e30"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "1.After consideration of above learning curve we can say that linear model was good-fit for this dataset beacause as we have seen that in the learning curve as epoch increases loss values gradually decreases.\n",
        "\n",
        "2.After trining this model we can expect that on the training set the performance should with time was not detoriated.\n",
        "\n",
        "3.As the loss will be low, which means that the model does a good job means model was good here.\n",
        "\n"
      ],
      "metadata": {
        "id": "kp6JbkNoUuL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87pFNt7DpG0H",
        "outputId": "859cf9c1-bc44-4b09-cb0c-175e274c9ed6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=(w * decision_function(X_test) + b)\n",
        "result = sigmoid(z)\n"
      ],
      "metadata": {
        "id": "AYbwHX4Xfd3B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = []\n",
        "for i in result:\n",
        "    if i >=0.5:\n",
        "        predict.append(1)\n",
        "    else:\n",
        "        predict.append(0)\n",
        "print(np.array(predict))"
      ],
      "metadata": {
        "id": "RNWxREENfuWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5fbdf3-e30e-4ebc-921c-8aff922a483b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqtKxO72oURz",
        "outputId": "b53f755d-2735-4288-c5a4-e50a166836ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTY7z2bd4Zx2"
      },
      "source": [
        "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM3odN1Z4Zx3"
      },
      "source": [
        "\n",
        "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
        "\n",
        "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
        "\n",
        "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
        "\n",
        "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
        "\n",
        "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}