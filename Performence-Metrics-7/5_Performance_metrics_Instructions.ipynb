{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "\n",
    "## A. Compute performance metrics for the given data '5_a.csv'\n",
    " <pre>  <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
    "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y_actual', 'y_probable'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a=pd.read_csv('5_a.csv',names=[\"y_actual\",\"y_probable\"],header = 0)\n",
    "df_a.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        y_actual  y_probable\n",
       "0           1.0    0.637387\n",
       "1           1.0    0.635165\n",
       "2           1.0    0.766586\n",
       "3           1.0    0.724564\n",
       "4           1.0    0.889199\n",
       "...         ...         ...\n",
       "10095       1.0    0.665371\n",
       "10096       1.0    0.607961\n",
       "10097       1.0    0.777724\n",
       "10098       1.0    0.846036\n",
       "10099       1.0    0.679507\n",
       "\n",
       "[10100 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10100 entries, 0 to 10099\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   y_actual    10100 non-null  float64\n",
      " 1   y_probable  10100 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 157.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yg8uUJvGAfCM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        y_actual  y_probable  y_predicted\n",
       "0           1.0    0.637387          1.0\n",
       "1           1.0    0.635165          1.0\n",
       "2           1.0    0.766586          1.0\n",
       "3           1.0    0.724564          1.0\n",
       "4           1.0    0.889199          1.0\n",
       "...         ...         ...          ...\n",
       "10095       1.0    0.665371          1.0\n",
       "10096       1.0    0.607961          1.0\n",
       "10097       1.0    0.777724          1.0\n",
       "10098       1.0    0.846036          1.0\n",
       "10099       1.0    0.679507          1.0\n",
       "\n",
       "[10100 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here for task A\n",
    "df_a['y_predicted'] = np.where(df_a['y_probable'] >= 0.5, float(1), float(0))     \n",
    "df_a.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "unique_classes_a = np.unique(df_a['y_actual'])\n",
    "print(unique_classes_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.   100.]\n",
      " [    0. 10000.]]\n"
     ]
    }
   ],
   "source": [
    "def compute_confusion_matrix(df_a):\n",
    "    \n",
    "    actual_y_values_a = df_a.iloc[:, 0].values\n",
    "    predicted_y_values_a = df_a.iloc[:, 2].values\n",
    "\n",
    "    unique_classes = np.unique(actual_y_values_a)\n",
    "\n",
    "    confusion_matrix = np.zeros((len(unique_classes_a), len(unique_classes_a)))\n",
    "    \n",
    "    for i in range(len(unique_classes_a)):\n",
    "        for j in range(len(unique_classes_a)):\n",
    "            confusion_matrix[i, j] = np.sum((unique_classes_a[i] == actual_y_values_a) & (unique_classes_a[j]  == predicted_y_values_a))\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "confusion_matrix_a = compute_confusion_matrix(df_a)\n",
    "\n",
    "print(confusion_matrix_a)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(confusion_matrix_a):\n",
    "    accuracy = (confusion_matrix_a[1, 1] + confusion_matrix_a[0, 0]) / (confusion_matrix_a[1, 1] + confusion_matrix_a[1, 0] + confusion_matrix_a[0, 1] + confusion_matrix_a[0, 0])\n",
    "    return accuracy\n",
    "    \n",
    "accuracy_score_a = compute_accuracy(confusion_matrix_a)\n",
    "\n",
    "print(accuracy_score_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "def compute_f1_score(confusion_matrix_a):\n",
    "    precision = confusion_matrix_a[1, 1] / (confusion_matrix_a[1, 1] + confusion_matrix_a[0, 1])\n",
    "    recall = confusion_matrix_a[1, 1] / (confusion_matrix_a[1, 1] + confusion_matrix_a[1, 0])\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "    \n",
    "f1_score_a = compute_f1_score(confusion_matrix_a)\n",
    "\n",
    "print(f1_score_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10100/10100 [00:07<00:00, 1277.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Custom function ROC-AUC Score for 5_a.csv:  0.48829900000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_all_thresholds_a(df_a):\n",
    "    tpr_a_for_all_thresholds = []\n",
    "    fpr_a_for_all_thresholds = []\n",
    "\n",
    "    sorted_df_a = df_a.sort_values(by=['y_probable'], ascending=False)\n",
    "\n",
    "    unique_probability_thresholds_a = sorted_df_a['y_probable'].unique()\n",
    "\n",
    "    for threshold in tqdm(unique_probability_thresholds_a):\n",
    "        sorted_df_a['y_predicted'] = np.where(sorted_df_a['y_probable'] >= threshold, 1, 0)\n",
    "        cm_a_sorted = compute_confusion_matrix(sorted_df_a)\n",
    "        tp = cm_a_sorted[1, 1]\n",
    "        fp = cm_a_sorted[0, 1]\n",
    "        fn = cm_a_sorted[1, 0]\n",
    "        tn = cm_a_sorted[0, 0]\n",
    "        tpr = tp / (tp + fn )\n",
    "        fpr = fp / (fp + tn)\n",
    "        \n",
    "        tpr_a_for_all_thresholds.append(tpr)\n",
    "        fpr_a_for_all_thresholds.append(fpr)\n",
    "\n",
    "    return tpr_a_for_all_thresholds, fpr_a_for_all_thresholds\n",
    "\n",
    "from tqdm import tqdm\n",
    "all_tpr_5_a, all_fpr_5_a = compute_all_thresholds_a(df_a)\n",
    "auc_score_5_a = np.trapz(all_tpr_5_a, all_fpr_5_a)\n",
    "print('My Custom function ROC-AUC Score for 5_a.csv: ', auc_score_5_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "\n",
    "\n",
    "## B. Compute performance metrics for the given data '5_b.csv'\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a>\n",
    "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_probable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_actual  y_probable\n",
       "0       0.0    0.281035\n",
       "1       0.0    0.465152\n",
       "2       0.0    0.352793\n",
       "3       0.0    0.157818\n",
       "4       0.0    0.276648"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b=pd.read_csv('5_b.csv',names=[\"y_actual\",\"y_probable\"],header = 0)\n",
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y_actual', 'y_probable'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10100 entries, 0 to 10099\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   y_actual    10100 non-null  float64\n",
      " 1   y_probable  10100 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 157.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_b.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b['y_predicted'] = np.where(df_b['y_probable'] >= 0.5, float(1), float(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(df_b['y_actual'])\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xlLVa-cVAfCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9761.  239.]\n",
      " [  45.   55.]]\n"
     ]
    }
   ],
   "source": [
    "# write your code here for task B\n",
    "cm_b = compute_confusion_matrix(df_b)\n",
    "print(cm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(cm_b):\n",
    "    accuracy = (cm_b[1, 1] + cm_b[0, 0]) / (cm_b[1, 1] + cm_b[1, 0] + cm_b[0, 1] + cm_b[0, 0])\n",
    "    return accuracy\n",
    "    \n",
    "accuracy_score_b = compute_accuracy(cm_b)\n",
    "\n",
    "print(accuracy_score_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "def compute_f1_score(cm_b):\n",
    "    precision = cm_b[1, 1] / (cm_b[1, 1] + cm_b[0, 1])\n",
    "    recall = cm_b[1, 1] / (cm_b[1, 1] + cm_b[1, 0])\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "    \n",
    "f1_score_b = compute_f1_score(cm_b)\n",
    "\n",
    "print(f1_score_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10100/10100 [00:08<00:00, 1217.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Custom function ROC-AUC Score for 5_b.csv:  0.9377570000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_tpr_5_b, all_fpr_5_b = compute_all_thresholds_a(df_b)\n",
    "auc_score_5_b = np.trapz(all_tpr_5_b, all_fpr_5_b)\n",
    "print('My Custom function ROC-AUC Score for 5_b.csv: ', auc_score_5_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "### C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data \n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_probable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_actual  y_probable\n",
       "0         0    0.458521\n",
       "1         0    0.505037\n",
       "2         0    0.418652\n",
       "3         0    0.412057\n",
       "4         0    0.375579"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c=pd.read_csv('5_c.csv',names=[\"y_actual\",\"y_probable\"],header = 0)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y_actual', 'y_probable'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2852 entries, 0 to 2851\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   y_actual    2852 non-null   int64  \n",
      " 1   y_probable  2852 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 44.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "eAPjewjzAfCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y      prob\n",
      "0  0  0.458521\n",
      "1  0  0.505037\n",
      "2  0  0.418652\n",
      "3  0  0.412057\n",
      "4  0  0.375579\n",
      "(2852, 2)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "def min_metric(data):\n",
    "    s = data['y'].value_counts()\n",
    "    P = s[1]\n",
    "    N = s[0]\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    metric={}\n",
    "    for elem in tqdm_notebook(data['y_probable']):\n",
    "        data['y_predicted']=predict(data,'y_probable',elem)\n",
    "        tpr.append(confusion_matrix['tp']/P)\n",
    "        fpr.append(confusion_matrix['fp']/N)\n",
    "        confusion_matrix=cal_vals(data,'y','y_pred')\n",
    "        metric_val=(500*confusion_matrix['fn'])+(100*confusion_matrix['fp'])\n",
    "        metric[elem]=metric_val\n",
    "        data.drop(columns=['y_pred'])\n",
    "    return(metric)\n",
    "\n",
    "data=pd.read_csv('5_c.csv')\n",
    "print(data.head())\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_values(sorted_df_c,thresh_hold):\n",
    "    y_pred=[]\n",
    "    for label in sorted_df_c['y_probable']:\n",
    "        if label<thresh_hold:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [00:04<00:00, 614.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# write your code for task C\n",
    "sorted_df_c = df_c.sort_values(by=['y_probable'], ascending=False)\n",
    "\n",
    "def min_metric(sorted_df_c):\n",
    "    metric={}\n",
    "    unique_probability_thresholds_c = sorted_df_c['y_probable'].unique()\n",
    "    \n",
    "    min_a = float('inf')\n",
    "    min_threshold = 0\n",
    "    \n",
    "    for elem in tqdm(sorted_df_c['y_probable']):\n",
    "        sorted_df_c['y_pred']= predicted_values(sorted_df_c,elem)\n",
    "        cm_c = compute_confusion_matrix(sorted_df_c)\n",
    "        metric_val=(500*cm_c[1,0])+(100*cm_c[0,1])\n",
    "        metric[elem]=metric_val\n",
    "        sorted_df_c.drop(columns=['y_pred'])\n",
    "    return (metric)\n",
    "\n",
    "result = min_metric(sorted_df_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the key:value pair for min value of the specified metric is- [0.2300390278970873] 141000.0\n"
     ]
    }
   ],
   "source": [
    "temp = min(result.values()) \n",
    "res = [key for key in result if result[key] == temp]\n",
    "print('the key:value pair for min value of the specified metric is-',res,temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "\n",
    "## D.</b></font> Compute performance metrics(for regression) for the given data 5_d.csv\n",
    "<pre>    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sVOj-bF9AfCd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_actual  y_predict\n",
       "0     101.0      100.0\n",
       "1     120.0      100.0\n",
       "2     131.0      113.0\n",
       "3     164.0      125.0\n",
       "4     154.0      152.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d=pd.read_csv('5_d.csv',names=[\"y_actual\",\"y_predict\"],header = 0)\n",
    "df_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_y_values_d = df_d.iloc[:, 0].values\n",
    "predicted_y_values_d = df_d.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.16569974554707\n"
     ]
    }
   ],
   "source": [
    "def calculate_mse(y_actual, y_predicted):\n",
    "    mse = np.mean((y_actual - y_predicted)**2)\n",
    "    return mse\n",
    "\n",
    "print(calculate_mse(actual_y_values_d, predicted_y_values_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.912029940096867\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_absolute_percentage_error(y_actual, y_predicted):\n",
    "    mape = np.mean((np.abs(y_actual - y_predicted)) / np.mean(y_actual)) * 100\n",
    "    return mape\n",
    "\n",
    "print(calculate_mean_absolute_percentage_error(actual_y_values_d, predicted_y_values_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uRhL1pheAfCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9563582786990937\n"
     ]
    }
   ],
   "source": [
    "# write your code for task 5d\n",
    "    \n",
    "def calculate_r2_score(y_train, y_predicted):\n",
    "    y_train_bar = y_train.mean()\n",
    "    # y_train_bar = np.mean(y_train)\n",
    "\n",
    "    sum_squared_residual = ((y_train - y_predicted)**2).sum()\n",
    "    sum_squared_total = ((y_train - y_train_bar)**2).sum()\n",
    "\n",
    "    return 1 - (sum_squared_residual/sum_squared_total)\n",
    "\n",
    "print(calculate_r2_score(actual_y_values_d, predicted_y_values_d))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
