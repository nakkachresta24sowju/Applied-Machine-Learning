{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Recommendation_system_assignment_final.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YeM0ZBWUVtXR"},"source":["# <font color='red'>SGD Algorithm to predict movie ratings</font>"]},{"cell_type":"markdown","metadata":{"id":"M2vyJqSlmmjM"},"source":["**There will be some functions that start with the word \"grader\" ex: grader_matrix(), grader_mean(), grader_dim() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"]},{"cell_type":"markdown","metadata":{"id":"AL6njTf8WBO0"},"source":["<pre>\n","1. Download the data from <a href='https://drive.google.com/open?id=1-1z7iDB52cB6_JpO7Dqa-eOYSs-mivpq'> here </a>\n","2. The data will be of this format, each data point is represented as a triplet of user_id, movie_id and rating \n","<table>\n","<tr><th>user_id</th><th>movie_id</th><th>rating</th></tr>\n","<tr><td>77</td><td>236</td><td>3</td></tr>\n","<tr><td>471</td><td>208</td><td>5</td></tr>\n","<tr><td>641</td><td>401</td><td>4</td></tr>\n","<tr><td>31</td><td>298</td><td>4</td></tr>\n","<tr><td>58</td><td>504</td><td>5</td></tr>\n","<tr><td>235</td><td>727</td><td>5</td></tr>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"73dhFsT0WSSB"},"source":["## <font color='red'>Task 1</font>"]},{"cell_type":"markdown","metadata":{"id":"HY0frS6EWaEV"},"source":["<font color='red'><b>Predict the rating for a given (user_id, movie_id) pair </b> </font>\n"]},{"cell_type":"markdown","metadata":{"id":"R-ISYxaVbT8L"},"source":["Predicted rating $\\hat{y}_{ij}$ for user i, movied j pair is calcuated as $\\hat{y}_{ij} = \\mu + b_i + c_j + u_i^T v_j$ , here we will be finding the best values of $b_{i}$ and $c_{j}$ using SGD algorithm with the optimization problem for N users and M movies is defined as"]},{"cell_type":"markdown","metadata":{"id":"8Aj8SXeQWlZd"},"source":["$$\n","L = \\min_{ b, c, \\{ u_i \\}_{i=1}^N, \\{ v_j \\}_{j=1}^M}\n","\\quad\n","\\alpha \\Big(\n","    \\sum_{j} \\sum_{k} v_{jk}^2 \n","    + \\sum_{i} \\sum_{k} u_{ik}^2 \n","    + \\sum_{i} b_i^2\n","    + \\sum_{j} c_i^2\n","    \\Big)\n","+ \\sum_{i,j \\in \\mathcal{I}^{\\text{train}}}\n","    (y_{ij} - \\mu - b_i - c_j - u_i^T v_j)^2\n","$$"]},{"cell_type":"markdown","metadata":{"id":"2Q5bnWyZXrM7"},"source":["<ul>\n","<li><span class=\"math\">\\(\\mu\\)</span> : scalar mean rating</li>\n","<li><span class=\"math\">\\(b_i\\)</span> : scalar bias term for user <span class=\"math\">\\(i\\)</span></li>\n","<li><span class=\"math\">\\(c_j\\)</span> : scalar bias term for movie <span class=\"math\">\\(j\\)</span></li>\n","<li><span class=\"math\">\\(u_i\\)</span> : K-dimensional vector for user <span class=\"math\">\\(i\\)</span></li>\n","<li><span class=\"math\">\\(v_j\\)</span> : K-dimensional vector for movie <span class=\"math\">\\(j\\)</span></li>\n","</ul>\n","\n"," $ \\ $\n"]},{"cell_type":"markdown","metadata":{"id":"q1cf4CunbEr4"},"source":["\n","\n","\n","*.  We will be giving you some functions, please write code in that functions only.\n","\n","*.  After every function, we will be giving you expected output, please make sure that you get that output. \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZWQyB5hfy3u7"},"source":["1. Construct adjacency matrix with the given data, assuming its graph and the weight of each edge is the rating given by user to the movie\n","\n","<img src='https://i.imgur.com/rmUCGMb.jpg' width=200>\n","\n","   you can construct this matrix like $A[i][j]=r_{ij}$ here $i$ is user_id, $j$ is movie_id and $r_{ij}$ is rating given by user $i$ to the movie $j$\n","\n","   Hint : you can create adjacency matrix using <a href='https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html'> csr_matrix</a>\n","\n","2. We will Apply SVD decomposition on the Adjaceny matrix <a href='https://stackoverflow.com/a/31528944/4084039'>link1</a>, <a href='https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/'> link2</a> and get three matrices $U, \\sum, V$ such that $U \\times \\sum \\times V^T = A$, <br> \n","if $A$ is of dimensions $N \\times M$ then <br>\n","U is of $N \\times k$, <br>\n","$\\sum$ is of $k \\times k$ and <br>\n","$V$ is $M \\times k$ dimensions. <br>\n","\n","   *.  So the matrix $U$ can be represented as matrix representation of users, where each row $u_{i}$ represents a k-dimensional vector for a user\n","\n","   *. So the matrix $V$ can be represented as matrix representation of movies, where each row $v_{j}$ represents a k-dimensional vector for a movie.\n","3. Compute $\\mu$ , $\\mu$  represents the mean of all the rating given in the dataset.(write your code in <font color='blue'>def m_u()</font>)\n","4. For each unique user initilize a bias value $B_{i}$ to zero, so if we have $N$ users $B$ will be a $N$ dimensional vector, the $i^{th}$ value of the $B$ will corresponds to the bias term for $i^{th}$ user (write your code in <font color='blue'>def initialize()</font>)\n","\n","5. For each unique movie initilize a bias value $C_{j}$ zero, so if we have $M$ movies $C$ will be a $M$ dimensional vector, the $j^{th}$ value of the $C$ will corresponds to the bias term for $j^{th}$ movie (write your code in <font color='blue'>def initialize()</font>)\n","\n","6. Compute dL/db_i (Write you code in <font color='blue'> def derivative_db()</font>)\n","7. Compute dL/dc_j(write your code in <font color='blue'> def derivative_dc()</font>\n","\n","8. Print the mean squared error with predicted ratings.\n","\n","<pre>\n","for each epoch:\n","    for each pair of (user, movie):\n","        b_i =  b_i - learning_rate * dL/db_i\n","        c_j =  c_j - learning_rate * dL/dc_j\n","predict the ratings with formula\n","</pre>\n","$\\hat{y}_{ij} = \\mu + b_i + c_j + \\text{dot_product}(u_i , v_j) $\n","\n","9. you can choose any learning rate and regularization term in the range $10^{-3}  \\text{ to } 10^2$  <br>\n","  \n","10. __bonus__: instead of using SVD decomposition you can learn the vectors $u_i$, $v_j$ with the help of SGD algo similar to $b_i$ and $c_j$ "]},{"cell_type":"code","metadata":{"id":"VlPVJoZ8JN4P"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2XrlYeuJOFq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3-aBnRepA6gy"},"source":["<br>"]},{"cell_type":"markdown","metadata":{"id":"IP_6xMAZA4mE"},"source":[" # <font color='red'>Task 2 </font>"]},{"cell_type":"markdown","metadata":{"id":"-9HCN_3WA2au"},"source":["As we know U is the learned matrix of user vectors, with its i-th row as the vector ui for user i. Each row of U can be seen as a \"feature vector\" for a particular user.\n","\n","The question we'd like to investigate is this: do our computed per-user features that are optimized for predicting movie ratings contain anything to do with gender?\n","\n","The provided data file <a href='https://drive.google.com/open?id=1PHFdJh_4gIPiLH5Q4UErH8GK71hTrzlY'>user_info.csv</a> contains an is_male column indicating which users in the dataset are male. Can you predict this signal given the features U?\n","\n","\n","> __Note 1__ : there is no train test split in the data, the goal of this assignment is to give an intution about how to do matrix factorization with the help of SGD and application of truncated SVD. for better understanding of the collabarative fillerting please check netflix case study. <br><br>\n","> __Note 2__ : Check if scaling of $U$, $V$ matrices improve the metric "]},{"cell_type":"markdown","metadata":{"id":"ovFCo1JCBIXM"},"source":["<br>\n","\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"iVJo-3njBQLf"},"source":["<font color='red'> Reading the csv file </font>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"hEhmfRD637EW","outputId":"07189bd2-eb44-43c7-f225-022cc41d0ee6"},"source":["import pandas as pd\n","data=pd.read_csv('ratings_train.csv')\n","data.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>772</td>\n","      <td>36</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471</td>\n","      <td>228</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>641</td>\n","      <td>401</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>312</td>\n","      <td>98</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58</td>\n","      <td>504</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  item_id  rating\n","0      772       36       3\n","1      471      228       5\n","2      641      401       4\n","3      312       98       4\n","4       58      504       5"]},"execution_count":23,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"66ibGJ74hCde","outputId":"627b068c-baa2-4751-f4d5-03a7c8e8b77b"},"source":["data.shape"],"execution_count":null,"outputs":[{"data":{"text/plain":["(89992, 3)"]},"execution_count":6,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"mvB8SDS_hW03"},"source":["<font color='red'>Create your adjacency matrix </font>"]},{"cell_type":"code","metadata":{"id":"t44MNT40hZQW"},"source":["from scipy.sparse import csr_matrix\n","adjacency_matrix = # write your code of adjacency matrix here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mCgC0WbhZTO"},"source":["adjacency_matrix.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4acJD4ujEtD6"},"source":["<font color='cyan'>Grader function - 1</font>"]},{"cell_type":"code","metadata":{"id":"2QuTzFBREsDV"},"source":["def grader_matrix(matrix):\n","  assert(matrix.shape==(943,1681))\n","  return True\n","grader_matrix(adjacency_matrix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U7VwkRNeHpWE"},"source":["**The unique items in the given csv file are 1662 only . But the id's vary from 0-1681 but they are not continuous and hence \n","you'll get matrix of size 943x1681.**"]},{"cell_type":"markdown","metadata":{"id":"gXDf1RCUBsYN"},"source":["<font color='red'> SVD decompostion</font>"]},{"cell_type":"markdown","metadata":{"id":"OJPWI9VwD_ih"},"source":["Sample code for SVD decompostion"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67},"id":"GATD35bmBszc","outputId":"b3f57c71-7ce6-4796-ab6c-e7af570a864c"},"source":["from sklearn.utils.extmath import randomized_svd\n","import numpy as np \n","matrix = np.random.random((20, 10))\n","U, Sigma, VT = randomized_svd(matrix, n_components=5,n_iter=5, random_state=None)\n","print(U.shape)\n","print(Sigma.shape)\n","print(VT.T.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(20, 5)\n","(5,)\n","(10, 5)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ePDgwALQEJoB"},"source":["<font color='red'>Write your code for SVD decompostion</font>"]},{"cell_type":"code","metadata":{"id":"ZYnsKBmFEIg3"},"source":["# Please use adjacency_matrix as matrix for SVD decompostion\n","# You can choose n_components as your choice"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83Vh4NoO_JyU"},"source":["<font color='red'>Compute mean of ratings</font>"]},{"cell_type":"code","metadata":{"id":"cBHuCn2QSEnl"},"source":["def m_u(ratings):\n","    '''In this function, we will compute mean for all the ratings'''\n","    # you can use mean() function to do this\n","    # check this (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) link for more details.\n","    \n","\n","    return "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iu1nn-1x3ebp"},"source":["mu=m_u(data['rating'])\n","print(mu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76ooYQIdG_tf"},"source":["<font color='cyan'>Grader function -2 </font>"]},{"cell_type":"code","metadata":{"id":"TZy1m67oG9r9"},"source":["def grader_mean(mu):\n","  assert(np.round(mu,3)==3.529)\n","  return True\n","mu=m_u(data['rating'])\n","grader_mean(mu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qSvAW1X94g3G"},"source":["<font color='red'>Initialize $B_{i}$ and $C_{j}$"]},{"cell_type":"markdown","metadata":{"id":"qsOl-4xq5aUG"},"source":["Hint : Number of rows of adjacent matrix corresponds to user dimensions($B_{i}$), number of columns of adjacent matrix corresponds to movie dimensions ($C_{j}$)"]},{"cell_type":"code","metadata":{"id":"AyEJqPka4lBW"},"source":["def initialize(dim):\n","    '''In this function, we will initialize bias value 'B' and 'C'.'''\n","    # initalize the value to zeros \n","    # return output as a list of zeros \n","\n","    \n","\n","    return "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nlae9QAQ43Xz"},"source":["dim= # give the number of dimensions for b_i (Here b_i corresponds to users)\n","b_i=initialize(dim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwuopn4HoEbP"},"source":["dim= # give the number of dimensions for c_j (Here c_j corresponds to movies)\n","c_j=initialize(dim)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nfPJ3_h6JIkI"},"source":["<font color='cyan'>Grader function -3 </font>"]},{"cell_type":"code","metadata":{"id":"dQhiNjw0Hz4m"},"source":["def grader_dim(b_i,c_j):\n","  assert(len(b_i)==943 and np.sum(b_i)==0)\n","  assert(len(c_j)==1681 and np.sum(c_j)==0)\n","  return True\n","grader_dim(b_i,c_j)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DTDK4ZR18MrZ"},"source":["<font color='red'>Compute dL/db_i</font>"]},{"cell_type":"code","metadata":{"id":"3NFzVC1N8S4L"},"source":["def derivative_db(user_id,item_id,rating,U,V,mu,alpha):\n","    '''In this function, we will compute dL/db_i'''\n","    return \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ilISrTeQ0f0v"},"source":["<font color='cyan'>Grader function -4 </font>"]},{"cell_type":"code","metadata":{"id":"Wt5ixEVZ043U"},"source":["def grader_db(value):\n","    assert(np.round(value,3)==-0.931)\n","    return True\n","U1, Sigma, V1 = randomized_svd(adjacency_matrix, n_components=2,n_iter=5, random_state=24)\n","# Please don't change random state\n","# Here we are considering n_componets = 2 for our convinence\n","alpha=0.01 \n","value=derivative_db(312,98,4,U1,V1,mu,alpha)\n","grader_db(value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Kp0hC_b9v60"},"source":["<font color='red'>Compute dL/dc_j</font>"]},{"cell_type":"code","metadata":{"id":"FAtSYMrc9UqJ"},"source":["def derivative_dc(user_id,item_id,rating,U,V,mu, alpha):\n","    '''In this function, we will compute dL/dc_j'''\n","    return \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lxkAm8aH1SBF"},"source":["<font color='cyan'>Grader function - 5 </font>"]},{"cell_type":"code","metadata":{"id":"RaIN9yie1US8"},"source":["def grader_dc(value):\n","    assert(np.round(value,3)==-2.929)\n","    return True\n","U1, Sigma, V1 = randomized_svd(adjacency_matrix, n_components=2,n_iter=5, random_state=24)\n","# Please don't change random state\n","# Here we are considering n_componets = 2 for our convinence\n","r=0.01 \n","value=derivative_dc(58,504,5,U1,V1,mu)\n","grader_dc(value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lg5XNbDWCIKI"},"source":["<font color='red'>Compute MSE (mean squared error) for predicted ratings</font>\n"]},{"cell_type":"markdown","metadata":{"id":"7WUjNy0TDQX6"},"source":["for each epoch, print the MSE value"]},{"cell_type":"markdown","metadata":{"id":"D2pCy1AKCafw"},"source":["<pre>\n","for each epoch:\n","\n","    for each pair of (user, movie):\n","\n","        b_i =  b_i - learning_rate * dL/db_i\n","\n","        c_j =  c_j - learning_rate * dL/dc_j\n","\n","predict the ratings with formula\n","</pre>\n","\n","$\\hat{y}_{ij} = \\mu + b_i + c_j + \\text{dot_product}(u_i , v_j) $"]},{"cell_type":"code","metadata":{"id":"kiKj-M6d2a-Y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTXYZFFUVSg5"},"source":["<font color='red'>Plot epoch number vs MSE </font>\n","\n","* epoch number on X-axis\n","* MSE on Y-axis"]},{"cell_type":"code","metadata":{"id":"igkkO3EvVRt6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NeWAGkT6C9kq"},"source":["<br>"]},{"cell_type":"markdown","metadata":{"id":"lkIQOOo1C9o7"},"source":["# <font color='red'> Task 2</font>"]},{"cell_type":"markdown","metadata":{"id":"9kl4Ryi_7E_T"},"source":["- For this task you have to consider the user_matrix U and the user_info.csv file.\n","- You have to consider is_male columns as  output features and rest as input features. Now you have to fit a model by posing this problem as binary classification task.\n","- You can apply any model like Logistic regression or Decision tree and check the performance of the model. \n","- Do plot confusion matrix after fitting your model and write your observations how your model is performing in this task.\n","\n","- Optional work- You can try scaling your U matrix.Scaling means changing the values of n_componenets while performing svd\n","  and then check your results."]},{"cell_type":"code","metadata":{"id":"c1FTc39gDdti"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7e_3BBsHpWO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3K5ZHmSHpWO"},"source":[""],"execution_count":null,"outputs":[]}]}